{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incubadora Santander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "from warnings import filterwarnings\n",
    "from IPython.display import HTML\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "import pandas\n",
    "import numpy\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"reproductoras_pesadas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtrado de datos de acuerdo a sexos\n",
    "df=df[df.sexoAnimales != \"Mixtos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fecha = pd.to_datetime(df.fecha)\n",
    "#df = df[[x.year != 2017 for x in df.fecha]]\n",
    "\n",
    "df['granjaGalpon'] = ['{} / {}'.format(x, y) for (x, y) in zip(df.granja, df.noDeGalpon)]\n",
    "#df.idLote = [x if x[-1] != 'A' else x[:-1] for x in df.idLote]\n",
    "df['pesoAveG'] = [x if x != 0.0 else np.nan for x in df.pesoAveG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['consumoAcumG', 'pesoAveG', 'mortalidadAcumuladaPor',\"uniformidadPor\",\"consumoAguaAveDiaMl\"]\n",
    "dl = df[(df.etapa == 'Levante')]\n",
    "\n",
    "dl_H = dl[dl.sexoAnimales == \"Hembras\"]\n",
    "dl_M = dl[dl.sexoAnimales == \"Machos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_Pivot = pd.merge(dl_H[['consumoAcumG', 'pesoAveG', 'mortalidadAcumuladaPor',\"uniformidadPor\",\"consumoAguaAveDiaMl\",\"idLote\",\"edadEnSemanas\",\"granjaGalpon\",\"fecha\"]],\n",
    "                    dl_M[['consumoAcumG', 'pesoAveG', 'mortalidadAcumuladaPor',\"uniformidadPor\",\"consumoAguaAveDiaMl\",\"idLote\",\"edadEnSemanas\",\"granjaGalpon\"]],\n",
    "                    left_on=[\"idLote\",\"edadEnSemanas\",\"granjaGalpon\"], right_on=[\"idLote\",\"edadEnSemanas\",\"granjaGalpon\"],\n",
    "        suffixes=('_Hembras', '_Machos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_Pivot[\"RelaciónPesoMachoHembras\"] = [x/y for x,y in zip(dl_Pivot.pesoAveG_Machos,dl_Pivot.pesoAveG_Hembras)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_colors = ['rgb(31, 119, 180)', 'rgb(255, 127, 14)',\n",
    "                         'rgb(44, 160, 44)', 'rgb(214, 39, 40)',\n",
    "                         'rgb(148, 103, 189)', 'rgb(140, 86, 75)',\n",
    "                         'rgb(227, 119, 194)', 'rgb(127, 127, 127)',\n",
    "                         'rgb(188, 189, 34)', 'rgb(23, 190, 207)']\n",
    "\n",
    "def plot_targetCat_boxplot(dfc, target,Categorical):\n",
    "    \"\"\"\n",
    "    Plot boxplot of input target by cluster\n",
    "    :param dfc: (pandas.DataFrame) matrix with targets, pcas and cluster labels\n",
    "    :param target: (str) name of the target to plot\n",
    "    :param Categorical: (str) name of the categorical variable\n",
    "    \"\"\"\n",
    "\n",
    "    # Asign Colors by Cluster\n",
    "    levels = dfc[Categorical].unique()\n",
    "    #colors = dict(zip(clusters, plotly_colors))\n",
    "\n",
    "    # Set Figure\n",
    "    fig = go.Figure(\n",
    "\n",
    "        # Figure Traces\n",
    "        data = [go.Box(\n",
    "            y=dfc[dfc[Categorical] == level][target],\n",
    "            name=level,jitter = 0.3,  pointpos = -1.8,\n",
    "    boxpoints = 'all', #marker=dict(color=colors[cluster]),\n",
    "        ) for level in levels],\n",
    "\n",
    "        # Figure Layout\n",
    "        layout = go.Layout(\n",
    "            xaxis=dict(title=target, tickformat='.2f'),\n",
    "            annotations=[dict(\n",
    "                text='Distribution of {} by Category in {}'.format(target,Categorical),\n",
    "                font=dict(size=24),\n",
    "                showarrow=False, x=0.0, xref='paper', xanchor='left', y=1.15, yref='paper', yanchor='top'\n",
    "            )]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Display Figure\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "targets = ['consumoAcumG', 'pesoAveG', 'mortalidadAcumuladaPor',\"uniformidadPor\",\"consumoAguaAveDiaMl\"]\n",
    "targets_hembras = [\"nacimientoPor\",\"pesoPromHuevoG\",\"posturaPor\",\"produccionHuevosParaIncubarPor\",\"haa\",\"pollosAA\",\"huevoIncAA\",\"conversionHuevoInc\"]\n",
    "for target in targets:\n",
    "    plot_targetCat_boxplot(df[(df.edadEnSemanas == 60) & (pd.notna(df[target]))],target,\"sexoAnimales\")\n",
    "print(\"Diferencia en resultados para hembras por línea genética\")    \n",
    "for target in targets_hembras:\n",
    "    plot_targetCat_boxplot(df[(df.edadEnSemanas == 60) & (pd.notna(df[target]))],target,\"lineaGenetica\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    fig = go.Figure()\n",
    "    dataset =dl_Pivot[dl_Pivot.edadEnSemanas == 20]\n",
    "    fig.add_trace(go.Scatter(x=dataset.fecha, y=dataset[target+\"_Hembras\"],\n",
    "                                mode='markers',\n",
    "                                name=target+\"_Hembras\",\n",
    "                                line = {'color':'rgb(0, 0, 122)' }\n",
    "                                    ))\n",
    "    fig.add_trace(go.Scatter(x=dataset.fecha, y=dataset[target+\"_Machos\"],\n",
    "                                mode='markers',\n",
    "                                name=target+\"_Machos\",\n",
    "                                line = {'color':'rgb(122, 0, 0)' }\n",
    "                                    ))\n",
    "    fig['layout'].update(title='Comparación de {} a semana 20 de levante'.format(target))\n",
    "    fig['layout']['xaxis'].update(title=\"Fecha\")\n",
    "    fig['layout']['yaxis'].update(title=\"{}\".format(target))\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histplot(var):\n",
    "    x = dff[var]\n",
    "    hist_data = [x]\n",
    "    group_labels = [var]\n",
    "    if var== \"conversionAlimenticia\":\n",
    "        fig = ff.create_distplot(hist_data, group_labels,bin_size=[.05])\n",
    "    elif var== \"kgm2DiaActivo\":\n",
    "        fig = ff.create_distplot(hist_data, group_labels,bin_size=[.025])    \n",
    "    else:\n",
    "        fig = ff.create_distplot(hist_data, group_labels)\n",
    "    fig['layout'].update(title='Distribución de la variable {}'.format(var))\n",
    "    iplot(fig, filename='Distplot - {}'.format(var))\n",
    "for i in range(len(targets)):    \n",
    "    histplot(targets[i])\n",
    "histplot(\"densidadKgm2\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histplotgen(var):\n",
    "    x1 = df[df.razaGen==\"ROSS\"][var]\n",
    "    x2 = df[df.razaGen==\"COBB\"][var]\n",
    "    hist_data = [x1,x2]\n",
    "    group_labels = ['ROSS', 'COBB']\n",
    "\n",
    "    if var== \"conversionAlimenticia\":\n",
    "        fig = ff.create_distplot(hist_data, group_labels,bin_size=[.05,.05])\n",
    "    elif var== \"kgm2DiaActivo\":\n",
    "        fig = ff.create_distplot(hist_data, group_labels,bin_size=[.025,0.025])      \n",
    "    else:\n",
    "        fig = ff.create_distplot(hist_data, group_labels)\n",
    "    fig['layout'].update(title='Distribución de la variable {} según raza'.format(var))\n",
    "    iplot(fig, filename='Distplot - {}'.format(var))\n",
    "for i in range(len(targets)):    \n",
    "    histplotgen(targets[i])\n",
    "histplotgen(\"densidadKgm2\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_matrix(dff, title='Correlation Matrix'):\n",
    "    \"\"\"\n",
    "    Plot Correlation Matrix\n",
    "    :param dff: (pandas.DataFrame) matrix with features to plot\n",
    "    \"\"\"\n",
    "\n",
    "    # Correlation Matrix\n",
    "    df = dff.dropna(how='any')\n",
    "    corr_mat = dff.corr()\n",
    "\n",
    "    # Hide Right Upper Part\n",
    "    for i in range(len(corr_mat)):\n",
    "        for j in range(len(corr_mat)):\n",
    "            if i > j:\n",
    "                corr_mat.iloc[i, j] = np.nan\n",
    "    corr_mat = corr_mat[corr_mat.columns.tolist()[::-1]]\n",
    "\n",
    "    # Set Figure\n",
    "    fig =  go.Figure(\n",
    "\n",
    "        # Figure Traces\n",
    "        data=[go.Heatmap(\n",
    "            x=corr_mat.columns, y=corr_mat.index, z=corr_mat.values,\n",
    "            colorscale='Picnic', zmax=1, zmin=-1\n",
    "        )],\n",
    "\n",
    "        # Figure Layout\n",
    "        layout=go.Layout(\n",
    "            height=400,\n",
    "            annotations=(\n",
    "                # Correlation Values as Annotations\n",
    "                [dict(\n",
    "                    x=x, y=y,\n",
    "                    text='' if np.isnan(corr_mat.loc[y][x]) else round(corr_mat.loc[y][x], 2),\n",
    "                    showarrow=False,\n",
    "                    font=dict(size=16)\n",
    "                ) for x in corr_mat.columns for y in corr_mat.index] +\n",
    "\n",
    "                # Figure Title\n",
    "                [dict(\n",
    "                    text=title,\n",
    "                    font=dict(size=24),\n",
    "                    showarrow=False, x=0.0, xref='paper', xanchor='left', y=1.15, yref='paper', yanchor='top'\n",
    "                )]\n",
    "            ),\n",
    "            margin=dict(l=150, t=50),\n",
    "            xaxis=dict(tickangle=-30),\n",
    "            # autosize=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Display Figure\n",
    "    iplot(fig)\n",
    "    \n",
    "\n",
    "def deal_with_nans(x, thresh=0.7):\n",
    "    \"\"\"\n",
    "    Deal with nan data\n",
    "    First drop columns for which there isn't enoug data.\n",
    "    Then fill missing values using median for continuous features and mode for categorical\n",
    "    Finally drop columns with no variability\n",
    "    :param x: (pandas.DataFrame) features dataframe\n",
    "    :param thresh: (float) features with missing values below the thresh are discarted\n",
    "    :return: (pandas.DataFrame) cleaned dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Drop rows with no data\n",
    "    dff = x.dropna(how='all')\n",
    "\n",
    "    # Drops columns with not enough data\n",
    "    dff.dropna(thresh=thresh * len(dff), axis=1, inplace=True)\n",
    "\n",
    "    # Identify continuous features\n",
    "    float_vars = [y for y in dff.columns if 'float' in str(dff[y].dtype)]\n",
    "\n",
    "    # Fill missing values\n",
    "    for feat in dff.columns:\n",
    "        if feat in float_vars:\n",
    "            # Fill continuous features with median\n",
    "            dff[feat] = dff[feat].fillna(dff[feat].median())\n",
    "        else:\n",
    "            # Fill categorical features with mode\n",
    "            dff[feat] = dff[feat].fillna(dff[feat].mode()[0])\n",
    "\n",
    "    # Drops columns with no variability\n",
    "    dff = dff[[y for y in dff.columns if len(dff[y].unique()) > 1]]\n",
    "\n",
    "    # Returns dataframe with no NaNs\n",
    "    return dff\n",
    "\n",
    "\n",
    "def clean_outliers(x, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Put all outliers on the confidence interval limit.\n",
    "    :param x: (pandas.DataFrame) matrix of features\n",
    "    :param alpha: (float) significance, 5% by default\n",
    "    :return: (pandas.DataFrame) matrix with no outliers\n",
    "    \"\"\"\n",
    "\n",
    "    # Cleaning Initialization\n",
    "    x_c = x.copy()\n",
    "\n",
    "    # Identification of categorical variables\n",
    "    cont_vars = [x for x in x_c.columns if 'float' in str(x_c[x].dtype)]\n",
    "\n",
    "    # If no continuous variables\n",
    "    if len(cont_vars) == 0:\n",
    "        return x_c\n",
    "\n",
    "    # Cleaning\n",
    "    for var in cont_vars:\n",
    "        ll = x_c[var].quantile(alpha)\n",
    "        ul = x_c[var].quantile(1-alpha)\n",
    "        x_c[var] = [ll if x < ll else (ul if x > ul else x) for x in x_c[var]]\n",
    "\n",
    "    # Return\n",
    "    return x_c\n",
    "\n",
    "\n",
    "def standarize(x):\n",
    "    \"\"\"\n",
    "    Normalize data\n",
    "    :param x: (pandas.DataFrame) matrix to normalize\n",
    "    :return: (pandas.DataFrame) normalized matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # Outliers Treatment\n",
    "    x_oc = clean_outliers(x)\n",
    "\n",
    "    scale = StandardScaler()\n",
    "    return pd.DataFrame(scale.fit_transform(x_oc), columns=x.columns, index=x_oc.index)\n",
    "\n",
    "\n",
    "def get_principal_componets(x, n_pca=None):\n",
    "    \"\"\"\n",
    "    Obtain the principal components from a set of continuous features.\n",
    "    If the number of components is not especified, the model find the minimum number\n",
    "    required to explain 90% of variance.\n",
    "    :param x: (pandas.DataFrame) matrix from which the components are extracted\n",
    "    :param n_pca: number of components\n",
    "    :return: (pandas.DataFrame) matrix of components\n",
    "    \"\"\"\n",
    "\n",
    "    # Standarization\n",
    "    x_std = standarize(x)\n",
    "\n",
    "    # Identify minimum number of components to explain 90% of the variability\n",
    "    if n_pca is None:\n",
    "        pca = PCA(random_state=1234)\n",
    "        pca.fit(x_std)\n",
    "        loadings = [round(y, 2) for y in pca.explained_variance_ratio_]\n",
    "        cumsumload = list(np.cumsum(loadings))\n",
    "        ncomps = [(y + 1, cumsumload[y]) for y in range(len(cumsumload))]\n",
    "        n_pca = [y for y in ncomps if y[1] >= 0.9][0][0]\n",
    "\n",
    "    # Calculate and return pcs\n",
    "    pca = PCA(n_components=n_pca, random_state=1234)\n",
    "    dp = pd.DataFrame(\n",
    "        pca.fit_transform(x_std),\n",
    "        columns=['PCA '+str(i+1) for i in range(n_pca)],\n",
    "        index=x.index\n",
    "    )\n",
    "    return dp\n",
    "\n",
    "\n",
    "def clusterize(x, n_clusters=3, pca=False):\n",
    "    \"\"\"\n",
    "    Performs KMeans clusterization.\n",
    "    If the number of components is not especified, the model finds\n",
    "    the number of clusters that maximize the silhouette score\n",
    "    :param x: (pandas.DataFrame) matrix of continuos features used for clusterization\n",
    "    :param n_clusters: (int) number of clusters\n",
    "    :param pca: (boolean) True if PCA must be applied before clusterization\n",
    "    :return: (pandas.DataFrame) matrix of clusters\n",
    "    \"\"\"\n",
    "    # Cleaning\n",
    "    x_c = deal_with_nans(x)\n",
    "\n",
    "    n_features = len(x.columns)\n",
    "    if n_features == 1:\n",
    "        # Binning\n",
    "        x_std = np.array(x_c).reshape(-1, 1)\n",
    "    else:\n",
    "        # PCA\n",
    "        x_std = get_principal_componets(x_c) if pca else standarize(x_c)\n",
    "\n",
    "    # Identify the number of clusters that maximize the silhouette score\n",
    "    if n_clusters is None:\n",
    "        cluster_span = [y for y in range(2, 7)]\n",
    "        ss = []\n",
    "        for i in cluster_span:\n",
    "            model = KMeans(n_clusters=i, random_state=1234)\n",
    "            model = model.fit(x_std)\n",
    "            mm = pd.DataFrame(model.fit_predict(x_std), columns=['labels'])\n",
    "            ss.append(round(silhouette_score(x_std, mm['labels']), 3))\n",
    "\n",
    "        ind = ss.index(max(ss))\n",
    "        n_clusters = cluster_span[ind]\n",
    "\n",
    "    # Clusterization\n",
    "    model = KMeans(n_clusters=n_clusters, random_state=1234)\n",
    "    model = model.fit(x_std)\n",
    "    dc = pd.DataFrame(model.fit_predict(x_std), columns=['cluster'], index=x_c.index)\n",
    "\n",
    "    # If there is a target, the clusters are sorted in accordance to that target\n",
    "    if 'target' in x_c.columns:\n",
    "        dc = pd.concat([x_c, dc], axis=1)\n",
    "        # dc['target'] = x_c['target']\n",
    "        ds = dc.groupby('cluster').mean()\n",
    "        ds.sort_values('target', ascending=False, inplace=True)\n",
    "        cluster_dict = dict(zip(ds.index, ['C' + str(i + 1) for i in range(n_clusters)]))\n",
    "        dc.cluster = [cluster_dict[y] for y in dc.cluster]\n",
    "        dc.sort_values('cluster', ascending=True, inplace=True)\n",
    "\n",
    "    else:\n",
    "        dc.cluster = dc.cluster + 1\n",
    "        dc.cluster = ['C'+str(c) for c in dc.cluster]\n",
    "\n",
    "    # Return\n",
    "    return dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlaciones en Producción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_hembras = [\"nacimientoPor\",\"pesoPromHuevoG\",\"posturaPor\",\"produccionHuevosParaIncubarPor\",\"haa\",\"pollosAA\",\"huevoIncAA\",\"conversionHuevoInc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_targets = {'mortalidadAcumuladaPor_Hembras': 'MORT_H', 'mortalidadAcumuladaPor_Machos': 'MORT_M', 'haa': 'HAA',\"nacimientoPor\":\"NACI_Por\",\"pollosAA\":\"POLLOSAA\",\"huevoIncAA\":\"HUEVOINCAA\", 'consumoAcumG_Hembras': 'CONS_H', 'consumoAcumG_Machos':'CONS_M', 'pesoAveG_Hembras': 'PESOAVG_H','pesoAveG_Machos': 'PESOAVG_M',\"RelaciónPesoMachoHembras\":\"PESO_M/PESO_H\"}\n",
    "cut_weeks = [25, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dp = df[df.etapa == 'Producción']\n",
    "dp = dp_Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = pd.DataFrame(index=dp.idLote.unique())\n",
    "for target in corr_targets:\n",
    "    dv = dp[dp.edadEnSemanas.isin(cut_weeks)]\n",
    "    dv = dv.pivot_table(index='idLote', columns='edadEnSemanas', values=target)\n",
    "    dv.columns = [corr_targets[target] + '_S' + str(int(x)) for x in dv.columns]\n",
    "    \n",
    "    dc = dc.join(dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.drop(columns=['HUEVOINCAA_S25', 'NACI_Por_S25'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_matrix(dc, 'Matriz de Correlación de Producción')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matriz de correlación Hembras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_Machos = [x  for x in dc.columns.unique() if \"_M\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_matrix(dc[col_Machos], 'Matriz de Correlación de Producción - Machos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matriz de correlación Hembras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_Hembras = [x  for x in dc.columns.unique() if x not in col_Machos]\n",
    "col_Hembras.append(\"PESO_M/PESO_H_S60\")\n",
    "col_Hembras.append(\"PESO_M/PESO_H_S25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_matrix(dc[col_Hembras], 'Matriz de Correlación de Producción - Hembras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_r_squared(y_real, model):\n",
    "    y_mean = np.mean(y_real)\n",
    "    ss_tot = sum([(y - y_mean)**2 for y in y_real])\n",
    "    ss_res = (model.resid_response**2).sum()\n",
    "    return round(1 - ss_res/ss_tot, 3)\n",
    "\n",
    "families = [\n",
    "    sm.families.Gaussian(),\n",
    "    sm.families.Binomial(),\n",
    "    sm.families.Gamma(),\n",
    "    sm.families.Gaussian(),\n",
    "    sm.families.InverseGaussian(),\n",
    "    sm.families.NegativeBinomial(),\n",
    "    sm.families.Poisson(),\n",
    "    sm.families.Tweedie(),\n",
    "]\n",
    "\n",
    "\n",
    "def perform_regression(x, y, alpha=0.05):\n",
    "    \n",
    "    dcc = dc[[x, y]].dropna(how='any')\n",
    "    dcc = clean_outliers(dcc)\n",
    "\n",
    "    min_aic = 1e100\n",
    "    for family in families:\n",
    "        try:\n",
    "            model = sm.GLM(dcc[y], sm.add_constant(dcc[x]), family=family)\n",
    "            model = model.fit()\n",
    "            model_aic = model.aic\n",
    "            if model_aic < min_aic:\n",
    "                min_aic = model_aic\n",
    "                best_model = model\n",
    "                best_family = family\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(best_model.summary())\n",
    "    r2 = calculate_r_squared(dcc[y], best_model)\n",
    "    print('R2: ', r2)\n",
    "    \n",
    "    significance = best_model.pvalues[x] < alpha and r2 > 0.2\n",
    "    preds = pd.DataFrame()\n",
    "    preds[x] = dcc[x]\n",
    "    preds[y] = best_model.predict()\n",
    "    \n",
    "    return significance, preds\n",
    "\n",
    "def perform_ols_regression(dataset, x, y):\n",
    "    dc = dataset.copy()\n",
    "    dcc = dc[[x, y]].dropna(how='any')\n",
    "    dcc = clean_outliers(dcc)\n",
    "    \n",
    "    mod = sm.OLS(dcc[y],  sm.add_constant(dcc[x]))\n",
    "    mod = mod.fit()\n",
    "    print(mod.summary())\n",
    "    \n",
    "    normal = sm.stats.jarque_bera(mod.resid)[1] > 0.01\n",
    "    mod_sig = mod.f_pvalue < 0.05\n",
    "    coef_sig = mod.pvalues[x] < 0.05\n",
    "    r2 = mod.rsquared\n",
    "    \n",
    "    preds = pd.DataFrame()\n",
    "    preds[x] = dcc[x]\n",
    "    preds[y] = mod.predict()\n",
    "    \n",
    "    return normal and mod_sig and coef_sig, preds, round(r2,2)\n",
    "    \n",
    "\n",
    "def plot_scatter(dataset, x, y, reg=True):\n",
    "    dc = dataset.copy()\n",
    "    dcc = dc[[x, y]].dropna(how='any')\n",
    "    dcc = clean_outliers(dcc)\n",
    "    data = []\n",
    "    \n",
    "    # Scatter\n",
    "    data.append(go.Scatter(\n",
    "        x=dcc[x], y=dcc[y], name='points', mode='markers'\n",
    "    ))\n",
    "    \n",
    "    # Regression\n",
    "    if reg:\n",
    "        sig, preds, r2 = perform_ols_regression(dataset, x, y)\n",
    "        if sig:\n",
    "            preds.sort_values(x, inplace=True)\n",
    "            data.append(go.Scatter(\n",
    "                x=preds[x], y=preds[y], name='reg + (R2: {})'.format(r2), mode='lines', line=dict(dash='dash')\n",
    "            ))\n",
    "    \n",
    "    # layout\n",
    "    lay = go.Layout(\n",
    "        xaxis=dict(title=x),\n",
    "        yaxis=dict(title=y)\n",
    "    )\n",
    "    \n",
    "    iplot(dict(layout=lay, data=data))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_scatter(dataset=dc, x='MORT_H_S60', y='HAA_S60', reg=False)\n",
    "plot_scatter(dataset=dc, x='PESO_M/PESO_H_S60', y='HAA_S60', reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(dataset=dc, x='MORT_H_S60', y='POLLOSAA_S60', reg=False)\n",
    "plot_scatter(dataset=dc, x='MORT_M_S60', y='POLLOSAA_S60', reg=False)\n",
    "plot_scatter(dataset=dc, x='PESO_M/PESO_H_S60', y='POLLOSAA_S60', reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(dataset=dc, x='MORT_H_S60', y='HUEVOINCAA_S60', reg=False)\n",
    "plot_scatter(dataset=dc, x='MORT_M_S60', y='HUEVOINCAA_S60', reg=False)\n",
    "plot_scatter(dataset=dc, x='PESO_M/PESO_H_S60', y='HUEVOINCAA_S60', reg=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(dw, cluster_targets, title='Coordinates'):\n",
    "    dataset = dw.copy()\n",
    "\n",
    "    dataset = dataset[cluster_targets]\n",
    "    dataset = deal_with_nans(dataset)\n",
    "    dataset['cluster'] = clusterize(dataset, pca=True)\n",
    "\n",
    "    # Soer Clusters by label\n",
    "    sort_label = cluster_targets[0]\n",
    "    dsort = dataset.groupby('cluster').median()\n",
    "    dsort.sort_values(sort_label, ascending=False, inplace=True)\n",
    "    cluster_translator = dict(zip(dsort.index, ['C3', 'C2', 'C1']))\n",
    "\n",
    "    dataset['cluster'] = [cluster_translator[x] for x in dataset.cluster]\n",
    "    dataset.sort_values('cluster', ascending=True, inplace=True)\n",
    "\n",
    "    dfc = dataset.copy()\n",
    "\n",
    "    # Identify targets\n",
    "    targets = [x for x in dfc.columns if 'PCA ' not in x and x != 'cluster']\n",
    "    x_t = dfc[targets]\n",
    "    y = dfc['cluster']\n",
    "\n",
    "    # Get Ordered Targets\n",
    "    ordered_targets = cluster_targets\n",
    "\n",
    "    # Asign Colors by Cluster\n",
    "    clusters = dfc.cluster.unique().tolist()\n",
    "    colors = {\n",
    "        'C3': '#2ca02c',\n",
    "        'C2': '#ff7f0e',\n",
    "        'C1': '#d62728'\n",
    "    }\n",
    "\n",
    "    # Set Figure\n",
    "    fig = go.Figure(\n",
    "\n",
    "        # Figure Traces\n",
    "        data=[go.Parcoords(\n",
    "            line=dict(\n",
    "                color=[clusters.index(x) for x in dfc['cluster']],\n",
    "                colorscale=[[clusters.index(x)/2, colors[x]] for x in clusters],\n",
    "            ),\n",
    "            dimensions= [dict(\n",
    "                label='Cluster',\n",
    "                values=[int(x.replace('C', '')) for x in dfc['cluster']],\n",
    "                tickvals=[int(x.replace('C', '')) for x in clusters],\n",
    "                ticktext=clusters\n",
    "            )] + [dict(\n",
    "                label=y,\n",
    "                values=dfc[y],\n",
    "                tickformat='.2f'\n",
    "            ) for y in ordered_targets]\n",
    "        )],\n",
    "\n",
    "        # Figure Layout\n",
    "        layout=go.Layout(\n",
    "            annotations=[dict(\n",
    "                text=title,\n",
    "                font=dict(size=24),\n",
    "                showarrow=False, x=0.0, xref='paper', xanchor='left', y=1.30, yref='paper', yanchor='top'\n",
    "            )],\n",
    "            margin=dict(b=50)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Display Figure\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.columns.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['PESOAVG_M_S25', #'PESOAVG_H_S25',\n",
    "           'POLLOSAA_S60', 'HUEVOINCAA_S60', 'HAA_S60', 'MORT_H_S60']\n",
    "plot_clusters(dc, targets, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "granjas = df[['idLote','granja']]\n",
    "granjas.drop_duplicates(inplace=True)\n",
    "granjas.set_index('idLote',inplace=True)\n",
    "granjas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dc.copy()\n",
    "\n",
    "dataset = dataset[['PESOAVG_M_S25', 'PESOAVG_H_S25', 'POLLOSAA_S60', 'HUEVOINCAA_S60', 'HAA_S60', 'MORT_H_S60']]\n",
    "dataset = deal_with_nans(dataset)\n",
    "dataset['cluster'] = clusterize(dataset, pca=True)\n",
    "dataset['granja'] =[granjas.loc[x,'granja'] for x in dataset.index]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_granja = dataset.pivot_table(index='granja',columns='cluster',values='HAA_S60',aggfunc='count', margins=True)\n",
    "cluster_granja.fillna(0,inplace=True)\n",
    "for cluster in cluster_granja.columns:\n",
    "    cluster_granja[cluster]=round((cluster_granja[cluster]/cluster_granja['All'])*100,1)\n",
    "cluster_granja.drop('All',inplace=True)\n",
    "cluster_granja.drop('All',inplace=True, axis=1)\n",
    "cluster_granja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlación entre Levante y Producción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_matrix(dpl,'Matriz de Correlación de Levante y  Producción')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_Machos_dlp = [x  for x in dpl.columns.unique() if \"_M\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_matrix(dpl[col_Machos_dlp],'Matriz de Correlación de Levante y  Producción - Machos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_Hembras_dlp = [x  for x in dpl.columns.unique() if x not in col_Machos_dlp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_matrix(dpl[col_Hembras_dlp],'Matriz de Correlación de Levante y  Producción - Hembras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpl.corr()[\"HAA\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(dpl, 'PESO_H_20', 'HAA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['PESO_M_20', \"MORT_H\",\"MORT_M\",'HAA', 'CONV_H']\n",
    "plot_clusters(dpl, targets, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(dpl, 'PESO_M_20', 'HAA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['PESO_H_20','PESO_M_20','PESO_M_25', 'HAA', 'CONV_H']\n",
    "plot_clusters(dpl, targets, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this IPython notebook is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
